{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcf2ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PM95Y\\source\\repos\\LSTM_for_text_completion\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "from src.data_utils import make_clean_data, tokenize_data, train_test_val_split\n",
    "from src.next_token_dataset import TweetsDataset\n",
    "from src.eval_transformer_pipeline import evaluate_pipeline\n",
    "from src.lstm_model import LSTM\n",
    "from src.lstm_train import lstm_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ce66ea",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ac6213",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_clean_data('data/tweets.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c21a2faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize_data('data/tweets_processed.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25ecc985",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, val = train_test_val_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0396de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 128\n",
    "train_ds = TweetsDataset(train[:10000], max_len)\n",
    "test_ds = TweetsDataset(test[:1000], max_len)\n",
    "val_ds = TweetsDataset(val[:1000], max_len)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=50, shuffle=False)\n",
    "test_dl = DataLoader(test_ds, batch_size=50, shuffle=False)\n",
    "val_dl = DataLoader(val_ds, batch_size=50, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cfe98f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilbert/distilgpt2')\n",
    "vocab_size = tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ebeb6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]c:\\Users\\PM95Y\\source\\repos\\LSTM_for_text_completion\\src\\next_token_dataset.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(x), torch.tensor(y)\n",
      " 10%|█         | 1/10 [01:57<17:41, 117.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 1.0362 | Val Loss: 0.797 | Val Accuracy: 89.01% | ROUGE-1 SCORE: 14.55% | ROUGE-2 SCORE: 1.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [05:21<22:25, 168.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 0.7602 | Val Loss: 0.757 | Val Accuracy: 89.47% | ROUGE-1 SCORE: 25.98% | ROUGE-2 SCORE: 2.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [08:45<21:30, 184.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 0.7049 | Val Loss: 0.746 | Val Accuracy: 89.63% | ROUGE-1 SCORE: 28.62% | ROUGE-2 SCORE: 3.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [12:07<19:08, 191.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 0.6638 | Val Loss: 0.738 | Val Accuracy: 89.71% | ROUGE-1 SCORE: 31.25% | ROUGE-2 SCORE: 4.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [15:35<16:27, 197.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 0.6306 | Val Loss: 0.748 | Val Accuracy: 89.68% | ROUGE-1 SCORE: 33.04% | ROUGE-2 SCORE: 4.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [19:03<13:25, 201.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Train Loss: 0.6035 | Val Loss: 0.758 | Val Accuracy: 89.71% | ROUGE-1 SCORE: 34.67% | ROUGE-2 SCORE: 4.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [22:39<10:17, 205.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Train Loss: 0.5785 | Val Loss: 0.767 | Val Accuracy: 89.69% | ROUGE-1 SCORE: 34.22% | ROUGE-2 SCORE: 4.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [26:05<06:51, 205.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Train Loss: 0.5589 | Val Loss: 0.779 | Val Accuracy: 89.67% | ROUGE-1 SCORE: 35.32% | ROUGE-2 SCORE: 4.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [29:41<03:29, 209.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Train Loss: 0.5391 | Val Loss: 0.786 | Val Accuracy: 89.65% | ROUGE-1 SCORE: 36.21% | ROUGE-2 SCORE: 4.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [33:16<00:00, 199.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.5213 | Val Loss: 0.791 | Val Accuracy: 89.69% | ROUGE-1 SCORE: 36.56% | ROUGE-2 SCORE: 4.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = LSTM(vocab_size)\n",
    "\n",
    "lstm_train(model, train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d926b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' i m sorry i ll be able to go to'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(model.generate(tokenizer.encode('hi how'), 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab9c576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'models/lstm_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188e9413",
   "metadata": {},
   "source": [
    "# Transformers pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05376531",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = AutoModelForCausalLM.from_pretrained('../distilgpt2').to('cuda')\n",
    "generator = pipeline(\"text-generation\", model=pretrained_model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b6295e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results, rouge = evaluate_pipeline(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb383b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awww that s a bummer you shoulda got david carr of thay.\\n\\nMitts\\nNathan\\nMy thoughts',\n",
       " 'is upset that he can t update his facebook by texting it and might cry as a resounding voice.',\n",
       " 'i dived many times for the ball managed to save 50 the reels.\\n\\n\\n\\n\\nSo I thought I could help the',\n",
       " 'my whole body feels itchy and like a cat.”\\nAs I',\n",
       " 'no it s not behaving at all i m mad why am i here because i can t ive been on a plane and i am not on a plane and i am not',\n",
       " 'not the whole ㅠ�',\n",
       " 'need a hunch on',\n",
       " 'hey long time no see yes rains a bit only a bit lol i m fi m u cant use a light bulb to light a lot more then I',\n",
       " 'nope they didn t h.\\n\\nIt',\n",
       " 'que me mu, p']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18008da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': np.float64(0.6375416956534943), 'rouge2': np.float64(0.5839876818800434), 'rougeL': np.float64(0.6368535018799146), 'rougeLsum': np.float64(0.6360259566412538)}\n"
     ]
    }
   ],
   "source": [
    "print(rouge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b338ffb1",
   "metadata": {},
   "source": [
    "# Итоги"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9389290c",
   "metadata": {},
   "source": [
    "Не удалось подключиться к ВМ, поэтому для экономии времени обучение проводилось на 10000 примерах и валидация - на 1000. Метрики ROUGE-1 и ROUGE-2 гораздо выше у предобученной модели трансформера (36.56% ROUGE-1 у LSTM против 63.75% у трансформера и 4.5% ROUGE-2 у LSTM против 58.4% у трансформера). Качество генерации текста (если сравнивать \"на глаз\") при этом у моделей примерно одинаковое. Однако стоит учесть, что distilgpt2 на текстах из sentiment140-датасета не обучалась (либо, если обучалась, то не только на них), и если нам необходима генерация текстов, специфичных для конкретного домена (в нашем случае, twitter), то лучше использовать собственноручно обученную LSTM (но обучить на полном датасете)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55de1fc",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
